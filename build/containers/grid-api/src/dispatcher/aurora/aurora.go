package aurora

import (
	"encoding/json"
	"errors"
	"fmt"
	log "github.com/Sirupsen/logrus"
	aurora_client "github.com/acquia/grid-api/dispatcher/aurora/client"
	scheduler "github.com/acquia/grid-api/dispatcher/scheduler"
	"github.com/acquia/grid-api/thrift/manifest"
	aurora_thrift "github.com/apache/aurora/api"
	"time"
)

const AURORA_EXECUTOR_NAME = "AuroraExecutor"

// AuroraRemoteScheduler is an implementation of dispatcher.RemoteScheduler.
type AuroraRemoteScheduler struct {
	host string
	port int
}

// NewAuroraRemoteScheduler creates an AuroraRemoteScheduler.
func NewAuroraRemoteScheduler(config *scheduler.SchedulerConfig) *AuroraRemoteScheduler {
	return &AuroraRemoteScheduler{
		host: config.RemoteHost,
		port: config.RemotePort,
	}
}

// acquireLock gets a lock from Aurora.
func (a *AuroraRemoteScheduler) acquireLock(lock_key *aurora_thrift.LockKey, session_key *aurora_thrift.SessionKey) (*aurora_thrift.Lock, error) {
	aurora_uri := a.AuroraUri(a.host, a.port)
	client := aurora_client.NewAuroraClient(aurora_uri)
	defer client.Close()
	client.Connect()
	response, err := client.Client.AcquireLock(lock_key, session_key)
	err = a.checkResponse(response, err, "Aurora lock creation failed")

	if err != nil {
		return nil, err
	}

	return response.Result_.AcquireLockResult_.Lock, err
}

// releaseLock releases a lock from Aurora generated by AuroraRemoteScheduler::acquireLock().
func (a *AuroraRemoteScheduler) releaseLock(lock *aurora_thrift.Lock, lockValidation aurora_thrift.LockValidation, session_key *aurora_thrift.SessionKey) error {
	aurora_uri := a.AuroraUri(a.host, a.port)
	client := aurora_client.NewAuroraClient(aurora_uri)
	defer client.Close()
	client.Connect()
	response, err := client.Client.ReleaseLock(lock, lockValidation, session_key)
	err = a.checkResponse(response, err, "Aurora lock release failed")

	return err
}

// Create implements RemoteScheduler::Create().
func (a *AuroraRemoteScheduler) Create(app *manifest.Application) (result *scheduler.SchedulerResult, err error) {
	result = scheduler.NewSchedulerResult()
	result.ExitCode = 0
	result.Output = "Job created."

	owner := a.GetOwner(app.Id)
	job_key := a.GetJobKey(app.Id)

	// @todo remove when done debugging
	//ulockKey := a.GetLockKey(job_key)
	//usessionKey := a.GetSessionKey()
	//ulock := aurora_thrift.NewLock()
	//ulock.Key = ulockKey
	//ulock.Token = "4207f995-1429-4d7f-ad57-66c3eab62105"
	//ulock.User = "UNSECURE"
	//ulock.TimestampMs = 1441745904752
	//err = a.releaseLock(ulock, aurora_thrift.LockValidation_UNCHECKED, usessionKey)

	// Acquire a lock.
	// @todo offer a force release option.
	lock_key := a.GetLockKey(job_key)
	session_key := a.GetSessionKey()
	lock, err := a.acquireLock(lock_key, session_key)
	if err != nil {
		result.ExitCode = 1
		result.Output = "Failed to acquire the lock required to create a job."
		return result, err
	}

	// Define our job.
	// @todo protect against nil values from the manifest.
	job_config := aurora_thrift.NewJobConfiguration()
	job_config.CronCollisionPolicy = aurora_thrift.CronCollisionPolicy_KILL_EXISTING
	job_config.TaskConfig = a.CreateTaskConfigFromApplication(app)
	// @todo what are offset and limit?
	job_config.Owner = owner
	job_config.InstanceCount = app.Copies.Max
	job_config.Key = job_key

	aurora_uri := a.AuroraUri(a.host, a.port)
	client := aurora_client.NewAuroraClient(aurora_uri)
	defer client.Close()
	client.Connect()

	log.Debug("JobConfig %+v", job_config)
	response, err := client.Client.CreateJob(job_config, lock, session_key)
	err = a.checkResponse(response, err, "Aurora job creation failed")

	// Release the lock.
	release_err := a.releaseLock(lock, aurora_thrift.LockValidation_CHECKED, session_key)
	if release_err != nil {
		error_message := fmt.Sprintf("Unable to release lock: %+v %s", lock, release_err.Error())
		log.Error(error_message)
	}

	// @todo better error handling.
	return result, err
}

// Update implements RemoteScheduler::Update().
func (a *AuroraRemoteScheduler) Update(app *manifest.Application) (result *scheduler.SchedulerResult, err error) {
	result = scheduler.NewSchedulerResult()
	result.ExitCode = 0
	result.Output = "Job updated."

	session_key := a.GetSessionKey()

	job_update := aurora_thrift.NewJobUpdateRequest()
	job_update.TaskConfig = a.CreateTaskConfigFromApplication(app)
	job_update.InstanceCount = app.Copies.Max
	job_update.Settings = aurora_thrift.NewJobUpdateSettings()

	// Most of the update settings come from the manifest.
	if app.UpdateConfig != nil {
		job_update.Settings.UpdateGroupSize = app.UpdateConfig.BatchSize
		job_update.Settings.MaxPerInstanceFailures = app.UpdateConfig.FailureThreshold
		job_update.Settings.MaxFailedInstances = app.UpdateConfig.FailureThreshold
		job_update.Settings.MaxWaitToInstanceRunningMs = app.UpdateConfig.MaxWait
		job_update.Settings.MinWaitInInstanceRunningMs = app.UpdateConfig.MinWait
		job_update.Settings.RollbackOnFailure = app.UpdateConfig.Rollback
		// @todo do we need this?
		//job_update.Settings.UpdateOnlyTheseInstances = nil
		job_update.Settings.WaitForBatchCompletion = app.UpdateConfig.WaitForBatch
		// @todo do we need this?
		//job_update.Settings.BlockIfNoPulsesAfterMs = 1000
	}

	aurora_uri := a.AuroraUri(a.host, a.port)
	client := aurora_client.NewAuroraClient(aurora_uri)
	defer client.Close()
	client.Connect()

	log.Debug("JobConfig %+v", job_update)
	timestamp := time.Now().UnixNano()
	message := fmt.Sprintf("Updating job via api at %d", timestamp)
	response, err := client.Client.StartJobUpdate(job_update, message, session_key)
	log.Debug("Update: %+v", response)
	err = a.checkResponse(response, err, "Aurora job update failed")

	// @todo better error handling.
	return result, err
}

// Kill implements RemoteScheduler::Kill().
func (a *AuroraRemoteScheduler) Kill(id *manifest.AppID) (result *scheduler.SchedulerResult, err error) {
	// Manually kill:
	// Most notably, you need the instances and the job key... and no lock if you haven't already created one manually!
	// curl -H "Content-Type: application/json" -X POST -d '[1,"killTasks",1,1,{"1":{"rec":{"7":{"set":["i32",1,0]},"11":{"set":["rec",1,{"1":{"str":"www-data"},"2":{"str":"devel"},"3":{"str":"foo"}}]}}},"2":{"rec":{"4":{"str":"UNAUTHENTICATED"},"5":{"str":"VU5BVVRIRU5USUNBVEVE"}}}}]' http://54.210.204.215:8081/api
	result = scheduler.NewSchedulerResult()
	result.ExitCode = 0
	result.Output = ""

	aurora_uri := a.AuroraUri(a.host, a.port)
	client := aurora_client.NewAuroraClient(aurora_uri)
	defer client.Close()
	client.Connect()

	job_key := a.GetJobKey(id)
	lock_key := a.GetLockKey(job_key)
	session_key := a.GetSessionKey()
	lock, err := a.acquireLock(lock_key, session_key)
	if err != nil {
		result.ExitCode = 1
		result.Output = "Failed to acquire the lock to kill a job."
		return result, err
	}

	task_query := aurora_thrift.NewTaskQuery()
	task_query.JobKeys = map[*aurora_thrift.JobKey]bool{
		job_key: true,
	}

	// Find the instances to kill.
	info, info_err := client.Client.GetTasksStatus(task_query)
	task_query.InstanceIds = make(map[int32]bool)
	if info_err == nil {
		if info.Result_.ScheduleStatusResult_.Tasks != nil {
			tasks := info.Result_.ScheduleStatusResult_.Tasks
			for i, _ := range tasks {
				task_query.InstanceIds[tasks[i].AssignedTask.InstanceId] = true
			}
		}
	}

	// @todo verify that response didn't fail silently.
	response, err := client.Client.KillTasks(task_query, lock, session_key)

	err = a.checkResponse(response, err, "Aurora job termination failed")

	_ = a.releaseLock(lock, aurora_thrift.LockValidation_CHECKED, session_key)

	return result, err
}

// Restart implements RemoteScheduler::Restart().
func (a *AuroraRemoteScheduler) Restart(id *manifest.AppID) (result *scheduler.SchedulerResult, err error) {
	result = scheduler.NewSchedulerResult()
	result.ExitCode = 0
	result.Output = "Job restarted."

	job_key := a.GetJobKey(id)

	// Acquire a lock.
	lock_key := a.GetLockKey(job_key)
	session_key := a.GetSessionKey()
	lock, err := a.acquireLock(lock_key, session_key)
	if err != nil {
		result.ExitCode = 1
		result.Output = "Failed to acquire the lock required to restart a job."
		return result, err
	}

	aurora_uri := a.AuroraUri(a.host, a.port)
	client := aurora_client.NewAuroraClient(aurora_uri)
	defer client.Close()
	client.Connect()

	// Find the instances to restart.
	task_query := aurora_thrift.NewTaskQuery()
	task_query.JobKeys = map[*aurora_thrift.JobKey]bool{
		job_key: true,
	}

	info, info_err := client.Client.GetTasksStatus(task_query)
	instance_ids := make(map[int32]bool)
	if info_err == nil {
		if info.Result_.ScheduleStatusResult_.Tasks != nil {
			tasks := info.Result_.ScheduleStatusResult_.Tasks
			for i, _ := range tasks {
				instance_ids[tasks[i].AssignedTask.InstanceId] = true
			}
		}
	}

	if len(instance_ids) == 0 {
		result.ExitCode = 1
		result.Output = "Job not restarted."
		return result, errors.New(result.Output)
	}

	response, err := client.Client.RestartShards(job_key, instance_ids, lock, session_key)
	err = a.checkResponse(response, err, "Aurora job restart failed")

	_ = a.releaseLock(lock, aurora_thrift.LockValidation_CHECKED, session_key)

	return result, err
}

// Validate implements RemoteScheduler::Validate().
func (a *AuroraRemoteScheduler) Validate(jobManifest *manifest.Manifest) (bool, error) {
	// @todo implement
	return true, nil
}

// State implements RemoteScheduler::State().
func (a *AuroraRemoteScheduler) State(id *manifest.AppID) (result *scheduler.SchedulerResult, err error) {
	// @todo implement
	return result, err
}

// checkResponse will check both the thrift resposne object as well as the
// transport error and respond with a unified error if necessary.
func (a *AuroraRemoteScheduler) checkResponse(response *aurora_thrift.Response, err error, message string) error {
	error_message := ""
	if err != nil {
		error_message = fmt.Sprintf("%s %v", message, err)
	}
	if response != nil && response.ResponseCode != aurora_thrift.ResponseCode_OK {
		error_message = fmt.Sprintf("%s: %s", message, response.Details)
		err = errors.New(error_message)
	}
	if err != nil {
		log.Error(error_message)
		return err
	}
	return nil
}

// CreateTaskConfigFromApplication generates a TaskConfig object using values from our manifest Application.
func (a *AuroraRemoteScheduler) CreateTaskConfigFromApplication(app *manifest.Application) *aurora_thrift.TaskConfig {
	owner := a.GetOwner(app.Id)
	job_key := a.GetJobKey(app.Id)

	container := aurora_thrift.NewContainer()
	// @todo we should really try to consolidate the container types between the
	// thrift one and the thermos one.
	mesos_container := MesosContainer{}
	mesos_container.Docker = MesosDockerContainer{}
	// If this is a docker job, configure the container.
	if app.AppConfig.SourceType == manifest.AppSourceType_DOCKER {
		container.Docker = aurora_thrift.NewDockerContainer()
		container.Docker.Image = app.AppConfig.Source
		container.Docker.Parameters = make([]*aurora_thrift.DockerParameter, 0)
		mesos_container.Docker.Image = app.AppConfig.Source
		mesos_container.Docker.ForcePullImage = true
		mesos_container.Docker.Privileged = false
		mesos_container.Docker.NetworkingMode = "HOST"
		mesos_container.Docker.PortMappings = []int{}
		// @todo are these mapped correctly?
		for key, value := range app.AppConfig.Parameters {
			p := aurora_thrift.NewDockerParameter()
			p.Name = key
			p.Value = value
			mp := MesosDockerParameter{}
			mp.Name = key
			mp.Value = value
			container.Docker.Parameters = append(container.Docker.Parameters, p)
			mesos_container.Docker.Parameters = append(mesos_container.Docker.Parameters, &mp)
		}
	}

	is_service := false
	if app.AppConfig.AppType == manifest.AppType_SERVICE {
		is_service = true
	}

	// health_check is created to match the data sent in mesos_job.HealthCheck
	// below.
	health_check := manifest.NewHealthCheck()
	if app.HealthCheck != nil {
		health_check.InitialIntervalSecs = app.HealthCheck.InitialIntervalSecs
		health_check.IntervalSecs = app.HealthCheck.IntervalSecs
		health_check.TimeoutSecs = app.HealthCheck.TimeoutSecs
		health_check.MaxConsecutiveFailures = app.HealthCheck.MaxConsecutiveFailures
		health_check.Endpoint = app.HealthCheck.Endpoint
		health_check.ExpectedResponse = app.HealthCheck.ExpectedResponse
		health_check.ExpectedResponseCode = app.HealthCheck.ExpectedResponseCode
	}

	// MesosJob is an interpretation of the data that Thermos receives from an
	// Aurora job config file in the form of a "Service" object. This needs to
	// be serialized in a way that Python can consume it and create a new
	// Service object
	mesos_job := &MesosJob{
		Name:        app.Id.Name,
		Role:        app.Id.Role,
		Environment: app.Id.Environment,
		Production:  &app.AppConfig.Production,
		Priority:    0,
		Task: &MesosTask{
			Name:             app.Id.Name,
			FinalizationWait: 30,
			MaxFailures:      1,
			MaxConcurrency:   0,
			Resources: &MesosResources{
				Disk: app.Resources.Disk.Size,
				Ram:  app.Resources.Ram,
				Cpu:  app.Resources.Cpu,
			},
			Processes: []*MesosProcess{
				&MesosProcess{
					Cmdline:     app.AppConfig.Command,
					Name:        app.Id.Name,
					Daemon:      false, // @todo real value
					Ephemeral:   false, // @todo real value
					MaxFailures: 1,     // @todo real value
					MinDuration: 5,     // @todo real value
					Final:       false, // @todo real value
				},
			},
			Constraints: []*string{},
		},
		Announce: &MesosAnnounce{
			PrimaryPort: "http",
			Portmap: map[string]string{
				"aurora": "http",
			},
		},
		HealthCheck:         health_check,
		Container:           &mesos_container,
		Service:             is_service,
		MaxTaskFailures:     1,
		CronCollisionPolicy: "KILL_EXISTING", // @todo can we get this string from thrift?
		EnableHooks:         false,
		// @todo can we know the cluster at creation time?
		// Cluster: "cluster-name",
	}

	// Create the task config.
	task_config := aurora_thrift.NewTaskConfig()
	task_config.JobName = app.Id.Name
	task_config.IsService = is_service
	// @todo verify the size units in the manifest
	task_config.NumCpus = app.Resources.Cpu
	task_config.RamMb = app.Resources.Ram
	task_config.DiskMb = app.Resources.Disk.Size
	// @todo what is our priority/task failures?
	task_config.Priority = 0
	task_config.MaxTaskFailures = 0
	task_config.Owner = owner
	task_config.Production = &app.AppConfig.Production
	task_config.Environment = app.Id.Environment
	task_config.Job = job_key
	// @todo what constraints do we have?
	task_config.Constraints = nil
	task_config.RequestedPorts = make(map[string]bool)
	if app.ExposedPorts != nil {
		for _, port := range app.ExposedPorts {
			task_config.RequestedPorts[port] = true
		}
	}
	task_config.ExecutorConfig = aurora_thrift.NewExecutorConfig()
	task_config.ExecutorConfig.Name = AURORA_EXECUTOR_NAME
	// @todo handle the marshalling error
	mesos_job_data, _ := json.Marshal(mesos_job)
	task_config.ExecutorConfig.Data = string(mesos_job_data)
	log.Debug("ExecutorConfig: %s", task_config.ExecutorConfig.Data)
	// @todo add email to manifest

	// If this is a docker job, configure the container.
	if app.AppConfig.SourceType == manifest.AppSourceType_DOCKER {
		task_config.Container = container
	}
	return task_config
}

// GetLockKey generates a new LockKey from the Aurora Thrift code.
func (a *AuroraRemoteScheduler) GetLockKey(job_key *aurora_thrift.JobKey) *aurora_thrift.LockKey {
	lock_key := aurora_thrift.NewLockKey()
	lock_key.Job = job_key
	return lock_key
}

// GetSessionKey generates a new SessionKey) from the Aurora Thrift code.
func (a *AuroraRemoteScheduler) GetSessionKey() *aurora_thrift.SessionKey {
	session_key := aurora_thrift.NewSessionKey()
	// @todo add authentication here.
	mechanism := "UNAUTHENTICATED"
	session_key.Mechanism = &mechanism
	session_key.Data = []byte("UNAUTHENTICATED")
	return session_key
}

// GetJobKey generates a new JobKey) from the Aurora Thrift code.
func (a *AuroraRemoteScheduler) GetJobKey(id *manifest.AppID) *aurora_thrift.JobKey {
	job_key := aurora_thrift.NewJobKey()
	job_key.Role = id.Role
	job_key.Environment = id.Environment
	job_key.Name = id.Name
	return job_key
}

// GetOwner generates a new Owner from the Aurora Thrift code.
func (a *AuroraRemoteScheduler) GetOwner(id *manifest.AppID) *aurora_thrift.Identity {
	owner := aurora_thrift.NewIdentity()
	// @todo who is the role?
	owner.Role = id.Role
	// @todo who is the user?
	owner.User = id.Name

	return owner
}

// AuroraUri is a helper to generate a URI string to contact the Aurora host.
func (a *AuroraRemoteScheduler) AuroraUri(host string, port int) string {
	return fmt.Sprintf("http://%s:%d/api", host, port)
}
